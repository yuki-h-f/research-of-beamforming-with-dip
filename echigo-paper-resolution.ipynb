{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "*Uncomment if running on colab* \n",
    "Set Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab \n",
    "\"\"\"\n",
    "# !git clone https://github.com/DmitryUlyanov/deep-image-prior\n",
    "# !mv deep-image-prior/* ./"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import libs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models import *\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "from models.downsampler import Downsampler\n",
    "\n",
    "from utils.sr_utils import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "imsize = -1 \n",
    "factor = 4 # 8\n",
    "enforse_div32 = 'CROP' # we usually need the dimensions to be divisible by a power of two (32 in this case)\n",
    "PLOT = True\n",
    "\n",
    "# To produce images from the paper we took *_GT.png images from LapSRN viewer for corresponding factor,\n",
    "# e.g. x4/zebra_GT.png for factor=4, and x8/zebra_GT.png for factor=8 \n",
    "path_to_image = 'data/sr/zebra_GT.png'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load image and baselines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Starts here\n",
    "imgs = load_LR_HR_imgs_sr(path_to_image , imsize, factor, enforse_div32)\n",
    "\n",
    "imgs['bicubic_np'], imgs['sharp_np'], imgs['nearest_np'] = get_baselines(imgs['LR_pil'], imgs['HR_pil'])\n",
    "\n",
    "if PLOT:\n",
    "    plot_image_grid([imgs['HR_np'], imgs['bicubic_np'], imgs['sharp_np'], imgs['nearest_np']], 4,12);\n",
    "    print ('PSNR bicubic: %.4f   PSNR nearest: %.4f' %  (\n",
    "                                        compare_psnr(imgs['HR_np'], imgs['bicubic_np']), \n",
    "                                        compare_psnr(imgs['HR_np'], imgs['nearest_np'])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN used in Echigo's paper"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ESPCN(nn.module):\n",
    "    only_luminance = True\n",
    "    input_upscale = False\n",
    "\n",
    "    def __init__(self, upscale=2):\n",
    "        super(ESPCN, self).__init__()\n",
    "        self.upscale = upscale\n",
    "        self.conv1 = nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, upscale ** 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(upscale ** 2, 40, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1)\n",
    "        self.upsampler = nn.Upsample(scale_factor=2, mode='bilenear')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.pixel_shuffle = nn.PixelShuffle(self.upscale)\n",
    "        self.features = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.conv2,\n",
    "            self.pixel_shuffle,\n",
    "            self.upsampler,\n",
    "            self.conv3,\n",
    "            self.conv4,\n",
    "            self.flatten\n",
    "        )\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        weights_with_relu = [\n",
    "            self.conv1.weight,\n",
    "            self.conv2.weight,\n",
    "            self.conv3.weight\n",
    "        ]\n",
    "\n",
    "        for w in weights_with_relu:\n",
    "            nn.init.orthogonal_(w, nn.init.calculate_gain('relu'))\n",
    "\n",
    "        nn.init.orthogonal_(self.conv4.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = ESPCN().to(device)\n",
    "summary(net, (3, 32, 32))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}